{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52269-code/NLP/blob/main/Lab8_T_Pranith_reddy_2403A52269.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Corpus**"
      ],
      "metadata": {
        "id": "sy0mDvq8RK1A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jTpWKKtgP6te"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D1=\"Fruits and vegetables are good for health.\"\n",
        "D2=\"Technology makes our life easier.\"\n",
        "D3=\"Mobile phones are very useful in daily life.\"\n",
        "D4=\"The teacher explained the lesson clearly.\"\n",
        "D5=\"I understood the topic after the class.\"\n",
        "D6=\"Music helps me relax after a long day.\"\n",
        "D7=\"Listening to songs makes me feel happy.\"\n",
        "D8=\"The car stopped working on the road.\"\n",
        "D9=\"The vehicle broke down in the middle of the street.\"\n",
        "D10=\"I love drinking coffee in the morning.\"\n"
      ],
      "metadata": {
        "id": "2hj0cWQ4Q5Fy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uni Gram Counts**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eImUb986RMkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "combined_text=f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "unigram_counts = collections.Counter(words)\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "id": "82GNuswrRICS",
        "outputId": "381e20ab-bee0-4320-9858-5e7c3e1eb1c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "the: 10\n",
            "in: 3\n",
            "are: 2\n",
            "makes: 2\n",
            "i: 2\n",
            "after: 2\n",
            "me: 2\n",
            "fruits: 1\n",
            "and: 1\n",
            "vegetables: 1\n",
            "good: 1\n",
            "for: 1\n",
            "health.: 1\n",
            "technology: 1\n",
            "our: 1\n",
            "life: 1\n",
            "easier.: 1\n",
            "mobile: 1\n",
            "phones: 1\n",
            "very: 1\n",
            "useful: 1\n",
            "daily: 1\n",
            "life.: 1\n",
            "teacher: 1\n",
            "explained: 1\n",
            "lesson: 1\n",
            "clearly.: 1\n",
            "understood: 1\n",
            "topic: 1\n",
            "class.: 1\n",
            "music: 1\n",
            "helps: 1\n",
            "relax: 1\n",
            "a: 1\n",
            "long: 1\n",
            "day.: 1\n",
            "listening: 1\n",
            "to: 1\n",
            "songs: 1\n",
            "feel: 1\n",
            "happy.: 1\n",
            "car: 1\n",
            "stopped: 1\n",
            "working: 1\n",
            "on: 1\n",
            "road.: 1\n",
            "vehicle: 1\n",
            "broke: 1\n",
            "down: 1\n",
            "middle: 1\n",
            "of: 1\n",
            "street.: 1\n",
            "love: 1\n",
            "drinking: 1\n",
            "coffee: 1\n",
            "morning.: 1\n",
            "Vocabulary Size= 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "lS0y_KtpVujx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = combined_text.lower().split()\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "id": "Veq51l4eR0wQ",
        "outputId": "d2ca86f6-b314-496a-91b4-69ec3c56914a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "in the: 2\n",
            "fruits and: 1\n",
            "and vegetables: 1\n",
            "vegetables are: 1\n",
            "are good: 1\n",
            "good for: 1\n",
            "for health.: 1\n",
            "health. technology: 1\n",
            "technology makes: 1\n",
            "makes our: 1\n",
            "our life: 1\n",
            "life easier.: 1\n",
            "easier. mobile: 1\n",
            "mobile phones: 1\n",
            "phones are: 1\n",
            "are very: 1\n",
            "very useful: 1\n",
            "useful in: 1\n",
            "in daily: 1\n",
            "daily life.: 1\n",
            "life. the: 1\n",
            "the teacher: 1\n",
            "teacher explained: 1\n",
            "explained the: 1\n",
            "the lesson: 1\n",
            "lesson clearly.: 1\n",
            "clearly. i: 1\n",
            "i understood: 1\n",
            "understood the: 1\n",
            "the topic: 1\n",
            "topic after: 1\n",
            "after the: 1\n",
            "the class.: 1\n",
            "class. music: 1\n",
            "music helps: 1\n",
            "helps me: 1\n",
            "me relax: 1\n",
            "relax after: 1\n",
            "after a: 1\n",
            "a long: 1\n",
            "long day.: 1\n",
            "day. listening: 1\n",
            "listening to: 1\n",
            "to songs: 1\n",
            "songs makes: 1\n",
            "makes me: 1\n",
            "me feel: 1\n",
            "feel happy.: 1\n",
            "happy. the: 1\n",
            "the car: 1\n",
            "car stopped: 1\n",
            "stopped working: 1\n",
            "working on: 1\n",
            "on the: 1\n",
            "the road.: 1\n",
            "road. the: 1\n",
            "the vehicle: 1\n",
            "vehicle broke: 1\n",
            "broke down: 1\n",
            "down in: 1\n",
            "the middle: 1\n",
            "middle of: 1\n",
            "of the: 1\n",
            "the street.: 1\n",
            "street. i: 1\n",
            "i love: 1\n",
            "love drinking: 1\n",
            "drinking coffee: 1\n",
            "coffee in: 1\n",
            "the morning.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "geXzUhZaSAlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "words = combined_text.lower().split()\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "id": "Mw8JuhhxR_Ej",
        "outputId": "25c82291-54d7-4411-aa47-e9e028970322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "fruits and vegetables: 1\n",
            "and vegetables are: 1\n",
            "vegetables are good: 1\n",
            "are good for: 1\n",
            "good for health.: 1\n",
            "for health. technology: 1\n",
            "health. technology makes: 1\n",
            "technology makes our: 1\n",
            "makes our life: 1\n",
            "our life easier.: 1\n",
            "life easier. mobile: 1\n",
            "easier. mobile phones: 1\n",
            "mobile phones are: 1\n",
            "phones are very: 1\n",
            "are very useful: 1\n",
            "very useful in: 1\n",
            "useful in daily: 1\n",
            "in daily life.: 1\n",
            "daily life. the: 1\n",
            "life. the teacher: 1\n",
            "the teacher explained: 1\n",
            "teacher explained the: 1\n",
            "explained the lesson: 1\n",
            "the lesson clearly.: 1\n",
            "lesson clearly. i: 1\n",
            "clearly. i understood: 1\n",
            "i understood the: 1\n",
            "understood the topic: 1\n",
            "the topic after: 1\n",
            "topic after the: 1\n",
            "after the class.: 1\n",
            "the class. music: 1\n",
            "class. music helps: 1\n",
            "music helps me: 1\n",
            "helps me relax: 1\n",
            "me relax after: 1\n",
            "relax after a: 1\n",
            "after a long: 1\n",
            "a long day.: 1\n",
            "long day. listening: 1\n",
            "day. listening to: 1\n",
            "listening to songs: 1\n",
            "to songs makes: 1\n",
            "songs makes me: 1\n",
            "makes me feel: 1\n",
            "me feel happy.: 1\n",
            "feel happy. the: 1\n",
            "happy. the car: 1\n",
            "the car stopped: 1\n",
            "car stopped working: 1\n",
            "stopped working on: 1\n",
            "working on the: 1\n",
            "on the road.: 1\n",
            "the road. the: 1\n",
            "road. the vehicle: 1\n",
            "the vehicle broke: 1\n",
            "vehicle broke down: 1\n",
            "broke down in: 1\n",
            "down in the: 1\n",
            "in the middle: 1\n",
            "the middle of: 1\n",
            "middle of the: 1\n",
            "of the street.: 1\n",
            "the street. i: 1\n",
            "street. i love: 1\n",
            "i love drinking: 1\n",
            "love drinking coffee: 1\n",
            "drinking coffee in: 1\n",
            "coffee in the: 1\n",
            "in the morning.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "3b9menmGSd_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"Fruits and\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Technology makes our\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"The teacher\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"I understood\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "id": "cD7qMAd7SnOn",
        "outputId": "add05da7-c18f-41be-babc-7e030c8809c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  vegetables is  1.0\n",
            "Given sequence: 'Fruits and', predicted next word: 'vegetables'\n",
            "probability of  life is  1.0\n",
            "Given sequence: 'Technology makes our', predicted next word: 'life'\n",
            "probability of  explained is  1.0\n",
            "Given sequence: 'The teacher', predicted next word: 'explained'\n",
            "probability of  the is  1.0\n",
            "Given sequence: 'I understood', predicted next word: 'the'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Bi-Gram Model**"
      ],
      "metadata": {
        "id": "qBl-eTA2TU2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "id": "HEi4NifmTXj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98353ffd-16de-40f9-8afa-bd2debca0be1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textfruits and vegetables\n",
            "probability of  are is  1.0\n",
            "Given sequence: 'fruits and vegetables', predicted next word: 'are'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "VE3G354oTcBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "id": "W4Nl4IXDTec0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e62e1e-9630-4e87-a9f5-b8c64b1c9a3b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Tri-Gram Model**"
      ],
      "metadata": {
        "id": "h9vQkgx2Tj61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "id": "hgaxUbcpThI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62af6ca0-cee1-4157-c0cb-9290f5fb3244"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textFruits and vegetables\n",
            "probability of  are is  1.0\n",
            "Given sequence: 'Fruits and vegetables', predicted next word: 'are'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening**"
      ],
      "metadata": {
        "id": "M-B_aq8pTp4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "id": "3tkh_J1JTqvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a1b799-aad6-4c69-de88-b878ce8caea3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am', predicted next word: 'No bigram found starting with 'am'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No bigram found starting with 'my'.'\n",
            "probability of understood is  0.034482758620689655\n",
            "probability of love is  0.034482758620689655\n",
            "Given sequence: 'professor I', predicted next word: 'understood'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "Iiky7VH0TxLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "id": "czO0w1jHTxl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea00253-12fa-418c-b29d-7b7f82ea42c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textFruits and vegetables\n",
            "probability of are is  0.03508771929824561\n",
            "Given sequence: 'Fruits and vegetables', predicted next word: 'are'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts based on laplace smoothening**"
      ],
      "metadata": {
        "id": "QeLMRSbqUElV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "id": "dvmUNfmnUE8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa18ff81-ca59-482e-dabc-c5ba6cc06320"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "Gs2lYMmCURqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "id": "X1WGdzQjUaTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b117d6-0f82-4817-98c4-8fe464816e7c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textFruits and vegetables\n",
            "probability of  are is  0.03508771929824561\n",
            "Given sequence: 'Fruits and vegetables', predicted next word: 'are'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "y-dSg-zVUc4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "id": "u0XJbNt9UfHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba9a31b-1e99-420a-f0f0-95443d217aed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am', predicted next word: 'No bigram found starting with 'am'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No bigram found starting with 'my'.'\n",
            "probability of understood is  0.05\n",
            "probability of love is  0.05\n",
            "Given sequence: 'professor I', predicted next word: 'understood'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "vWmH2nkwUxgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "id": "mZtDCbZ-UyWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80944a5-06d0-4214-8a97-ebe8530f7986"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textFruits and\n",
            "probability of vegetables is  0.05172413793103448\n",
            "Given sequence: 'Fruits and', predicted next word: 'vegetables'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "VgrnTCDVU03X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "id": "xN0cFqmgU3an",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10fd76cc-d0ac-4129-c2e2-cb46ffb7d560"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "_TDoQRKOVGmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "id": "AeawtUr6VI1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5844b3c3-86ac-497d-cf9d-c72490a82b5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textFruits and vegetables\n",
            "probability of  are is  0.05172413793103448\n",
            "Given sequence: 'Fruits and vegetables', predicted next word: 'are'\n"
          ]
        }
      ]
    }
  ]
}